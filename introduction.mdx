---
title: Introduction
---

Literal is a an all in one **observability**, **evaluation** and **analytics** platform for building **production-grade LLM apps**.

<Note>
  Click [here](https://github.com/Chainlit/chainlit) if you are looking for the
  Chainlit Open Source App Framework
</Note>

Literal covers a wide range of use cases, from conversational applications to task automation.

# Key Features

1. **Observability**: Setup data ingestion from your LLM app (including latency, feedback, files, prompts, token count and more) in a few minutes with our SDKs. Literal provides a unified view of all your data in one place.

<Frame caption="Example of an OpenAI assistant thread">
  <img src="/images/openai-assistant.png" />
</Frame>

2. **Prompt Evaluation**: Evaluate your prompt performances against your own datasets. Literal integrates with open source evaluation frameworks and let's you manipulate datasets both from the platform and programmatically.

3. **Product & User Analytics**: Gain insights into your users and how they use your product. Literal provides traditional analytics as well as LLM powered analytics like Topic Analysis.

<Frame caption="Literal Dashboard">
  <img src="/images/analytics.png" />
</Frame>
