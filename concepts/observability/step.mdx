---
title: "Step"
---

A Step is a fundamental building block within a [Thread](/concepts/observability/thread) that represents a single unit of interaction or operation.

Steps are versatile and can encompass various types of activities, such as sending a message, making a call to a large language model (LLM), or executing a custom function.

By organizing interactions into Steps, the Literal AI platform enables users to structure, visualize, and analyze the flow of conversations or processes in a granular and meaningful way.

## Types of Steps

There are several types of Steps, each serving a distinct purpose.

<Frame caption="A Thread with Steps and Tags.">
  <img src="/images/thread-steps.svg" alt="A Thread with Steps and Tags." />
</Frame>

### Run

A [`run` step](/concepts/observability/run) signifies the execution of an agent or a chain that takes multiple steps. Unlike other step types, it does not have to be part of a Thread.

This is useful if you are monitoring non conversational use cases.

### Message

A `message` step represents a message exchange within a Thread. There are two primary subtypes of message steps:

- **User Message**: This type of step is used to log messages sent by the user. It helps in tracking user inputs and requests.
- **Assistant Message**: This step logs messages generated by the assistant or application in response to user inputs.

### Tool

A `tool` step is used to document interactions with external tools or services. This step type is particularly useful for applications that interact with external APIs, databases, or services.

### LLM

An `llm` step is used to document interactions with large language models (LLMs). This step type is particularly useful for applications that leverage AI models, such as GPT-3, for generating responses, content, or performing analysis.

<Warning>Steps of type `llm` require input messages. Attempts to create `llm` steps without either `generation.messages` (chat API) or `generation.prompt` (completion API) yield a `run` step.</Warning>

## Implementing Steps

Possible `"type"`s are: `"run"`, `"tool"`, `"llm"`, `"embedding"`, `"retrieval"`, `"rerank"`, `"undefined"`, `"user_message"`, `"assistant_message"`, `"system_message"`.

<CodeGroup>

```python Python
import os
from literalai import LiteralClient

literal_client = LiteralClient(api_key=os.getenv("LITERAL_API_KEY"))

# You can change the step type
@literal_client.step(type="run")
def my_run():
    # Implement your custom logic here
    return "Success"

with literal_client.thread() as thread:
    literal_client.message(content="Hello World", type="assistant_message", name="My Assistant")
    my_run()
    
# Network requests by the SDK are performed asynchronously.
# Invoke flush_and_stop() to guarantee the completion of all requests prior to the process termination.
# WARNING: If you run a continuous server, you should not use this method.
client.flush_and_stop()
```

```typescript TypeScript
import { LiteralClient, Step, Thread } from "@literalai/client";

const literalClient = new LiteralClient(process.env["LITERAL_API_KEY"]);

// Run example
async function myRun(thread: Thread) {
  const run = thread.step({
    name: "My Run",
    type: "run",
    input: { content: "My run Input" },
  });

  // Implement your custom logic here
  const response = { content: "Success" };

  run.output = response;
  await run.send();

  return response;
}

async function main() {
  const thread = literalClient.thread();
  // Message example
  await thread
    .step({
      output: { content: "Hello World" },
      type: "assistant_message",
      name: "My Assistant",
    })
    .send();

  await myRun(thread);
}

```

</CodeGroup>


## Visualize the Steps on Literal AI

Click [here](https://cloud.getliteral.ai/thread/b3b61ec8-0d8a-444d-9e70-d6929c1129d1) for an interactive example. 

<Frame caption="Output on the platform">
  <img src="/images/step-example.png" alt="A thread on the platform" />
</Frame>

## Metadata

Metadata serves as a powerful tool for enriching objects with additional context, details, or configuration that can be instrumental in customizing and enhancing the functionality of each object. Specifically, the metadata field is available on Thread, Step, User, and Generation objects within the platform.

**How to add metadata to a Run or a Step**

<CodeGroup>

```python Python
import os
from literalai import LiteralClient

from dotenv import load_dotenv
load_dotenv()

literal_client = LiteralClient(api_key=os.getenv("LITERAL_API_KEY"))

@literal_client.step(type="run", name="my_step")
def my_step(input_message=None):
    current_step = literal_client.get_current_step()
    # some code, llm call, tool call, etc.
    current_step.metadata = {"region": "europe"}
    answer = "answer"
    return answer

my_step("Hello")

literal_client.flush_and_stop()
```

```typescript TypeScript
import { LiteralClient } from "@literalai/client";

const literalClient = new LiteralClient(process.env["LITERAL_API_KEY"]);

// The Assistant could have intermediary steps
async function myFunction(question:string) {
  const run = literalClient.run({
    name: "My Assistant Run",
    input: { content: question },
    metadata: { region: "europe" },
  });

  // Implement your assistant logic here
  await new Promise((r) => setTimeout(r, 1000));
  const response = { content: "My assistant response" };

  run.output = response;
  await run.send();

  return response;
}

myFunction("hello")
  .then(() => process.exit(0))
  .catch((error) => console.error(error));
```

</CodeGroup>

## Attachment

An attachment is a file that has been generated or processed by a Step. Learn more about attachments and multimodality [here](/concepts/observability/multimodal).

## Tags

Just like Threads, you can add Tags to single Steps. For more info, see [this section](/concepts/observability/tags).