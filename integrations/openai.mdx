---
title: "OpenAI"
---

<Note>
  We only support the OpenAI python package starting at version `1.0.0`. We
  don't support the Assistant API yet.
</Note>

The OpenAI integration allows you to generate an LLM Step automatically for each call to the OpenAI API.


<CodeGroup>
```python Python
import os
from literalai import LiteralClient
from openai import OpenAI

"""
You need to call the `instrument_openai` method from the Literal client to
enable the integration. Call it before any OpenAI API call.
"""
openai_client = OpenAI()
literal_client = LiteralClient(api_key=os.getenv("LITERAL_API_KEY"))
literal_client.instrument_openai()


@literal_client.thread()
def main():
    completion = openai_client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {
                "role": "user",
                "content": "What is the country with the longest name?",
            }
        ],
    )

    print(completion.choices[0].message.content)


main()
literal_client.wait_until_queue_empty()
```
</CodeGroup>
Here is how it looks on the Literal platform:

<Frame>
  <img
    src="/images/one-llm-step.png"
    alt="A thread with an OpenAI step on the platform"
  />
</Frame>
