---
title: Overview
---

Literal is an all in one **observability**, **evaluation** and **analytics** platform for building **production-grade LLM apps**.

It covers a wide range of use cases, from conversational applications to task automation. Literal can be used with any LLM framework, for example [Chainlit](http://localhost:3000/integrations/chainlit) and [LangChain](http://localhost:3000/integrations/langchain). It integrates well with [OpenAI](http://localhost:3000/integrations/openai), [Anthrophic, Mistral and many other LLM providers](http://localhost:3000/integrations/llm-providers).

Literal is developed by Chainlit, builders of the open-source Conversational AI Python framework [Chainlit](https://github.com/Chainlit/chainlit).

# Key Features

1. **Observability**: Monitor your LLM app (including conversations, intermediary steps, feedback, files, prompts, token consumption) in a few minutes with our SDKs. Literal provides a unified view of all your data in one place.

2. **Dataset**: Create datasets mixing production data and hand written examples to run non regression tests.

3. **Online Evals**: Evaluate your threads and runs in real time using off the shelf and custom evaluators.

4. **Prompt Collaboration**: Safely iterate, version and deploy prompts directly from Literal.

## Next up

<Card title="Install the Literal SDK" icon="code" href="/get-started/installation">
  Learn more about Literal's Concepts and Entities
</Card>