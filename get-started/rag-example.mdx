---
title: RAG Example
---

Let's say we have a simple LLM application that takes a user input, performs a retrieval step and generates the final response with an LLM.

The code for this application would look like this:

<CodeGroup>
```python Python
import asyncio

async def semantic_search(question: str):
  # Fake semantic search
  await asyncio.sleep(1)

  # Return fake results
  return ["chunk 1", "chunk 2", "chunk 3"]

async def generate_response(question: str, search_results: list):
  # Fake response generation
  await asyncio.sleep(2)

  return "Fake answer"

async def main():
  question = input("What is your question?")
  search_results = await semantic_search(question)
  answer = await generate_response(question, search_results)
  print(answer)

if __name__ == "__main__":
  asyncio.run(main())
```
</CodeGroup>

## Logging the conversation with Literal

First, we initialize the Literal client.
<CodeGroup>
```python Python
from literalai import LiteralClient

client = LiteralClient()
```
</CodeGroup>

### Logging the steps

In this example we have 2 steps: `semantic_search` and `generate_response`. We can use the `step` decorator to log these steps.

<CodeGroup>
```python Python
@client.step(type="retrieval")
async def semantic_search(question: str):
  ...

@client.step(type="llm")
async def generate_response(question: str, search_results: list):
  ...
```
</CodeGroup>

### Logging the run

<CodeGroup>
```python Python
@client.step(type="run")
async def run_rag(question: str):
  results = await semantic_search(question)
  answer = await generate_response(question, results)
  return answer  
```
</CodeGroup>

### Logging the thread

A [thread](/concepts/thread) is a sequence of steps that are related to each other. In our example, we have a single thread.
To create a thread, we use the `thread` decorator.

<CodeGroup>
```python Python
@client.thread
async def main():
  ...
```
</CodeGroup>

### Logging the user question and final answer

Finally, we can log the user question and the final answer using `client.message`.

<CodeGroup>
```python Python
@client.thread
async def main():
  question = input("What is your question?")
  client.message(content=question, type="user_message", name="User")
  answer = await run_rag(question)
  client.message(content=answer, type="assistant_message", name="Assistant")
  print(answer)
```
</CodeGroup>

### Full code

<CodeGroup>
```python Python
import asyncio
from literalai import LiteralClient

client = LiteralClient()

@client.step(type="retrieval")
async def semantic_search(question: str):
  await asyncio.sleep(1)
  return ["chunk 1", "chunk 2", "chunk 3"]

@client.step(type="llm")
async def generate_response(question: str, search_results: list):
  await asyncio.sleep(2)
  return "Fake answer"

@client.step(type="run")
async def run_rag(question: str):
  results = await semantic_search(question)
  answer = await generate_response(question, results)
  return answer

@client.thread
async def main():
  question = input("What is your question?")
  client.message(content=question, type="user_message", name="User")
  answer = await run_rag(question)
  client.message(content=answer, type="assistant_message", name="Assistant")
  print(answer)

if __name__ == "__main__":
  asyncio.run(main())
  client.wait_until_queue_empty()
```
</CodeGroup>

## Running the example in Python

To run the example, you need to install the Literal client:

```bash
pip install literalai
```

Then, you can run the example:

```bash
python example.py
```

On the Literal platform, you will see the following thread being logged:

<Frame caption="Rendering of the Thread">
  <img src="/images/python-example.jpg" />
</Frame>
